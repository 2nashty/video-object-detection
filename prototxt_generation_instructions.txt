If you want to pretrain a model on an existing model, follow the 
instructions on the flickr-style finetuning example:
https://github.com/BVLC/caffe/tree/master/examples/finetune_flickr_style
To avoid a loss of nan, change the weight_filler types from gaussian to xavier,
and make sure the base learning rate is 0.001 or lower.
Also make sure you change the two base_lr fields of the layer you're
resetting to random weights to 10 and 20 (rather than 1 and 2)

If you want to train a model from scratch, follow these instructions:
After completeing these instructions, you will have made these 3 files:
train_val.protxt, solver.protxt, and deploy.prototxt

Use absolute paths for simplicity.

First, copy the model's train_val.prototxt to
data/imagenet/<wnid_dir>/images/<dataset>/aux
Change the files for each "source:" and "mean_file:" line to the lmbd
files and image mean created by prepare_data.py.
Find the last layer that contains a "num_output" field and change that to
the number of categories (in my case, two: one positive, one negative).
I also change the batch_size to 64, in case I run out of memory
on my macbook.

Copy the model's solver.prototxt to
data/imagenet/<wnid_dir>/images/<dataset>/aux
Change the "net:" path to the path to the train_val.prototxt you just created.
Change the "snapshot_prefix:" to
data/imagenet/<wnid_dir>/snapshots/images/<dataset>/snapshots/snapshot
The snapshots directory must exist, and the "snapshot" will be the prefix of
"_iter_100..."
Change the "server_mode:" to CPU
Change the "snapshot:" to 1000. On my macbook, it takes 3 minutes per 20
iterations, so this produces one snapshot per half hour. On a K40 machine
training the bvlc_reference_caffenet, training the
bvlc_refference_caffenet on 1000 ImageNet categories takes 26 seconds per
20 iterations, which is ~5.2 ms per image, so I think they're training on about
5100 images. I'm training on about 4500 images, with equal numbers of negative
and positive images.
Don't bother reducing "max_iter", because you can interrupt training at any time.
Change "test_iter" to 1000. It takes a long time to test, so we want to do
this infrequently, but its purpose is to help us identify when we begin to
overfit, which helps us select which snapshot to use to detect objects.

Copy this to a new file called deploy.prototxt:

```
name: "<the name in the train_val.prototxt>"
input: "data"
input_dim: 10
input_dim: 3
input_dim: 224 # or whatever the crop_size is in train_val.prototxt
input_dim: 224
```

Append to that all layers in train_val.prototxt.
Delete the first few layers that don't have a "bottom" field.
Delete all pramaters that have to do exclusively with learning.
e.g.:
  - blobs_lr
  - weight_decay
  - weight_filler
  - bias_filler
Delete the "accuracy" layer and any layer after it (probably the softmax)
Append to the file this final layer:

```
# R-CNN classification layer made from R-CNN ILSVRC13 SVMs.
layers {
  name: "fc-rcnn"
  type: INNER_PRODUCT
  bottom: <name of layer right above this one>
  top: "fc-rcnn"
  inner_product_param {
    num_output: <change this to the number of categories>
  }
}
```
In the last layer before the R-CNN layer that contains a "num_output" field,
change that value to the number of categories (in my case, 2).

Then train the model until you see its test accuracy decreases significantly.
This decrease indicates the model is overfitting. Simply kill train.py and
use an earlier snapshot of the caffemodel to detect objects.

References for generating deploy.prototxt:
  https://github.com/BVLC/caffe/issues/1245
  https://github.com/BVLC/caffe/issues/261
